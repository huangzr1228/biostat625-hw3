---
title: "LinearModel_guide"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LinearModel_guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# LinearModel.new
## Introduction
The LinearModel.new package is created to perform the linear regression by ordinary least squares (OLS) and calculate the statistical measures of residuals, coefficients, and other significant statistics of the linear regression. 

With the input of the formula and data, the package will return the data frame of results.<br>
Statistical measures of residuals: minimum residual, 1Q residual, median residual, 3Q residual and maximum residual  
Coefficients: estimate, standard error, t value and p value  
Other statistics: residual standard error, R-squared, adjusted R-squared, F statistic and p value for F test

## Installation
You can install the development version of LinearModel.new from [GitHub]GitHub(https://github.com/huangzr1228/biostat625-hw3) with:
```{r}
install.packages("LinearModel.new")
devtools::install_github("huangzr1228/LinearModel.new")
```

## Usage
The function LinearReg() in the R package "LinearModel.new" could be used in this way
1. Load the ‚ÄùLinearModel.new" package into the R session
2. Load the data sets (built-in datasets or simulated datasets or other datasets)
3. Call the function LinearReg() in LinearReg(formula, data)
formula: The model requires to be fitted, described as "response variable ~ explanatory variables"
data: A data frame of the explanatory variables in the model
4. Return the data frame of all results, including the statistical measures of residuals, coefficients, and other significant statistics

```{r setup}
library(LinearModel.new)
library(bench)
```
### Example 1 (simple linear regression for buit-in datasets)
```{r}
LinearReg(Murder ~ UrbanPop, data = USArrests)
```

### Example 2 (simple linear regression for simulated data sets)
```{r}
x <- c(1, 2, 3, 4, 5)
y <- c(1.5, 3.0, 4.5, 6.0, 8.5)
df <- data.frame(y = y, x = x)
LinearReg(y ~ x, data = df)
```
### Example 3 (multiple linear regression for buit-in datasets)
```{r}
LinearReg(Murder ~ Assault + UrbanPop + Rape, data = USArrests)
```

### Example 4 (multiple linear regression for simulated data sets)
```{r}
set.seed(123)
x1 <- rnorm(50)
x2 <- rnorm(50)
x3 <- rnorm(50)
y <- 1 + 2 * x1 + 3.5 * x2 + 7 * x3 + rnorm(50)
df1 <- data.frame(y = y, x1 = x1, x2 = x2, x3 = x3)
LinearReg(y ~ x1 + x2 + x3, data = df1)
```

## Comparison
Compare the results from the new function LinearReg() with the function lm() and summary()
Take the Example 3 shown above as an example
```{r}
new_model <-
  LinearReg(Murder ~ Assault + UrbanPop + Rape, data = USArrests)
lm_model <-
  lm(Murder ~ Assault + UrbanPop + Rape, data = USArrests)
lm_summary <- summary(lm_model)
lm_summary
```

### Residuals
```{r}
residuals <- lm_model$residuals
residuals_min <- min(residuals)
residuals_1Q <- quantile(residuals, prob = 0.25)
residuals_median <- median(residuals)
residuals_3Q <- quantile(residuals, 0.75)
residuals_max <- max(residuals)
```

Test the correctness and efficiency of the minimum residual Residual_Min
```{r}
correctness_check <- all.equal(new_model$Residuals[["Residual_Min"]],
                               residuals_min,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$Residuals[["Residual_Min"]],
                                 residuals_min,
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of the 1Q residual Residual_1Q
```{r}
correctness_check <- all.equal(new_model$Residuals[["Residual_1Q"]],
                               unname(residuals_1Q["25%"]),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(
  new_model$Residuals[["Residual_1Q"]],
  unname(residuals_1Q["25%"]),
  iterations = 10,
  check = FALSE
)
print(benchmark_results)
```

Test the correctness and efficiency of the median residual Residual_Median
```{r}
correctness_check <- all.equal(new_model$Residuals[["Residual_Median"]],
                               residuals_median,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$Residuals[["Residual_Median"]],
                                 residuals_median,
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of the 3Q residual Residual_3Q
```{r}
correctness_check <- all.equal(new_model$Residuals[["Residual_3Q"]],
                               unname(residuals_3Q["75%"]),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(
  new_model$Residuals[["Residual_3Q"]],
  unname(residuals_3Q["75%"]),
  iterations = 10,
  check = FALSE
)
print(benchmark_results)
```

Test the correctness and efficiency of the maximum residual Residual_Max
```{r}
correctness_check <- all.equal(new_model$Residuals[["Residual_Max"]],
                               residuals_max,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <-
  bench::mark(new_model$Residuals[["Residual_Max"]],
              residuals_max,
              iterations = 10,
              check = FALSE)
print(benchmark_results)
```

### Coefficients
Test the correctness and efficiency of the Estimate \( \hat{\beta} \)
```{r}
estimates <- as.vector(new_model2$Coefficients$Estimate)
names(estimates) <- rownames(new_model$Coefficients)

correctness_check <- all.equal(estimates,
                               coef(lm_model),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(estimates,
                                 coef(lm_model),
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of the Standard Error \( SE(\hat{\beta}) \)
```{r}
stderror <- unname(as.vector(new_model$Coefficients$Std_Error))

correctness_check <- all.equal(stderror,
                               unname(lm_summary$coefficients[, "Std. Error"]),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(
  stderror,
  unname(lm_summary$coefficients[, "Std. Error"]),
  iterations = 10,
  check = FALSE
)
print(benchmark_results)
```

Test the correctness and efficiency of the t value
```{r}
tvalue <- as.vector(new_model$Coefficients$t_value)
names(tvalue) <- rownames(new_model$Coefficients)

correctness_check <- all.equal(tvalue,
                               lm_summary$coefficients[, "t value"],
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(tvalue,
                                 lm_summary$coefficients[, "t value"],
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of the p value
```{r}
pvalue <- as.vector(new_model$Coefficients$p_value)
names(pvalue) <- rownames(new_model$Coefficients)
  
correctness_check <- all.equal(pvalue,
                               lm_summary$coefficients[, "Pr(>|t|)"],
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(pvalue,
                                 lm_summary$coefficients[, "Pr(>|t|)"],
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

### Other statistics
Test the correctness and efficiency of Residual standard error \( \sigma \)
```{r}
correctness_check <- all.equal(new_model$ModelStats$Residual_Std_Error,
                               lm_summary$sigma,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$ModelStats$Residual_Std_Error,
                                 lm_summary$sigma,
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of R-squared\( R^2 \)
```{r}
correctness_check <- all.equal(new_model$ModelStats$R_Squared,
                               lm_summary$r.squared,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$ModelStats$R_Squared,
                                 lm_summary$r.squared,
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of Adjusted R-squared \( \bar{R}^2 \)
```{r}
correctness_check <- all.equal(new_model$ModelStats$Adj_R_Squared,
                               lm_summary$adj.r.squared,
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$ModelStats$Adj_R_Squared,
                                 lm_summary$adj.r.squared,
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of F statistic
```{r}
correctness_check <- all.equal(new_model$ModelStats$F_Statistic,
                               unname(lm_summary$fstatistic["value"]),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$ModelStats$F_Statistic,
                                 unname(lm_summary$fstatistic["value"]),
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

Test the correctness and efficiency of the p value for F test
```{r}
correctness_check <- all.equal(new_model$ModelStats$P_Value_F,
                               unname(
                 pf(
                   lm_summary$fstatistic[1],
                   lm_summary$fstatistic[2],
                   lm_summary$fstatistic[3],
                   lower.tail = FALSE
                 )
               ),
                               tolerance = 1e-5)
print(correctness_check)

benchmark_results <- bench::mark(new_model$ModelStats$P_Value_F,
                                 unname(
                 pf(
                   lm_summary$fstatistic[1],
                   lm_summary$fstatistic[2],
                   lm_summary$fstatistic[3],
                   lower.tail = FALSE
                 )
               ),
                                 iterations = 10,
                                 check = FALSE)
print(benchmark_results)
```

The Examples 1, 3, 4, and others can be tested using the same method as applied in Example 2.
